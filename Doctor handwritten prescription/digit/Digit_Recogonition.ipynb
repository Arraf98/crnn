{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a79e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "\n",
    "# Use a white background for matplotlib figures\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8432548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b19a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1750bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58df5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d79ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 32 # you can change this\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014dcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel(input_size, hidden_size=32, out_size=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3ed345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.307187795639038\n",
      "outputs.shape :  torch.Size([128, 10])\n",
      "Sample outputs :\n",
      " tensor([[ 0.0144,  0.0176, -0.1472, -0.0503,  0.0693,  0.0148,  0.0277,  0.3956,\n",
      "          0.2551,  0.0013],\n",
      "        [-0.0281,  0.0428, -0.0148, -0.0247,  0.0721,  0.1571,  0.1011,  0.3299,\n",
      "          0.0634, -0.0138]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Loss:', loss.item())\n",
    "    break\n",
    "\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129d7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bd5268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model (on GPU)\n",
    "model = MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea45138c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 2.304603099822998, 'val_acc': 0.09716796875}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b88a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.2345, val_acc: 0.9319\n",
      "Epoch [1], val_loss: 0.1928, val_acc: 0.9424\n",
      "Epoch [2], val_loss: 0.1833, val_acc: 0.9432\n",
      "Epoch [3], val_loss: 0.1796, val_acc: 0.9425\n",
      "Epoch [4], val_loss: 0.1566, val_acc: 0.9542\n"
     ]
    }
   ],
   "source": [
    "history += fit(5, 0.5, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55911b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test dataset\n",
    "test_dataset = MNIST(root='data/', \n",
    "                     train=False,\n",
    "                     transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2951e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "        xb = img.unsqueeze(0)\n",
    "        yb = model(xb)\n",
    "        _, preds  = torch.max(yb, dim=1)\n",
    "        return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afeaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'digit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f1f90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2 , Predicted: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885ac5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = test_dataset[1839]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd670246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('digit.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141b0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8455d5b13bcdb7ac8ae0bc5b4208eef9274fc59d9d9f4f560e91e25deeec1295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
